{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "236867b3-9008-4f72-945a-59103be0eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "99ad55b0-4082-477a-96e9-ea4aa39a5880",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/krushna/Downloads/archive-3/Data_Train.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[375], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/krushna/Downloads/archive-3/Data_Train.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[1;32m    505\u001b[0m         io,\n\u001b[1;32m    506\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    507\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    508\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    509\u001b[0m     )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1564\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1565\u001b[0m     )\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1570\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1420\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/krushna/Downloads/archive-3/Data_Train.xlsx'"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data = pd.read_excel(\"/Users/krushna/Downloads/archive-3/Data_Train.xlsx\")\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85e133-9a98-4cae-be09-607009ee8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a631e70e-3780-4b9a-b2a1-3e0cbef96745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values \n",
    "data.isnull().mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eebc73a-245d-4f6e-9a9d-0db586e06c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are very less missing values \n",
    "#We can use CCA\n",
    "data.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2353b46e-86d3-458b-97c3-f703783f8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff543f-cb9e-49f5-8e04-97f5c61aad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the data for Date_of_Journey\n",
    "print(data['Date_of_Journey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427b5d-f6f2-463b-81f6-203176cf7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Day_of_Journey'] = pd.to_datetime(data.Date_of_Journey, format = \"%d/%m/%Y\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085f5b8-b078-48fa-b9d6-713fc1abe156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month_of_Journey'] = pd.to_datetime(data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a60c2-24e9-4291-9e25-54b66a83e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year_of_Journey'] = pd.to_datetime(data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57eb3ad-81cc-41d3-a659-7a4321a25d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Date_of_Journey'], axis=1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd731ba6-941c-42ed-a0d2-4b2efd473c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fd4b8-e323-4c18-b6b3-15a635bf8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data for Dep_Time\n",
    "print(data['Dep_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80fe17-d762-4b88-a24a-387399fe3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Dep_min'] = pd.to_datetime(data.Dep_Time).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc07b2-7893-4311-81cf-17205720c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Dep_hour'] = pd.to_datetime(data.Dep_Time).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af40dc-a0b1-4c08-a6f9-c89cbfd1a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Dep_Time'], axis=1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7484dd-b3c5-4803-afc5-839fc3e650c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a5c02805-f0a8-43d1-a7d5-84f1afca0637",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Arrival_Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Arrival_Time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[376], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cleaning data for Arrival_Time\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArrival_Time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Arrival_Time'"
     ]
    }
   ],
   "source": [
    "# Cleaning data for Arrival_Time\n",
    "print(data['Arrival_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73193e-5293-40b3-82c9-c5c4902da9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Arr_minute'] = pd.to_datetime(data.Arrival_Time).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa498e4-3f75-431c-9206-243bc48bddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Arr_hour'] = pd.to_datetime(data.Arrival_Time).dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b073677-951f-46fe-8d28-4aa97cd531be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Arrival_Time'], axis=1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92066435-d484-4879-a526-505d017c994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a76b5-f32c-492a-bbc2-75a9f5ab8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data for Duration\n",
    "\n",
    "duration = list(data['Duration'])\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2: # If value != 2h 0m OR 0h 2m \n",
    "        if 'h' in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i].strip() \n",
    "\n",
    "duration_hours = []\n",
    "duration_minute = []\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = 'h')[0]))\n",
    "    duration_minute.append(int(duration[i].split(sep = 'm')[0].split()[-1]))        \n",
    "\n",
    "data['duration_hours']= duration_hours\n",
    "data['duration_minute'] = duration_minute\n",
    "data.drop('Duration', axis =1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4d1b9-509c-4b7f-85d2-ffd414904c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ee91e-f689-4201-bc46-00f5dbb8f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning categorical data which is Airline \n",
    "data['Airline'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6434b-ec71-45ce-be9f-a064c7d07dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing jet airways beacause it's no more there \n",
    "df = data[data['Airline'] != 'Jet Airways']\n",
    "# Removing jet airways beacause it's no more there \n",
    "df = data[data['Airline'] != 'Jet Airways Business']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb19dad-1aa7-4eea-bb02-3037930ee5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74a5d5-be3f-4e8c-b2a1-5d816e53e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot separate histograms for each airline\n",
    "airlines = df['Airline'].unique()\n",
    "n_airlines = len(airlines)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, airline in enumerate(airlines, 1):\n",
    "    plt.subplot((n_airlines // 3) + 1, 3, i)\n",
    "    plt.hist(df[df['Airline'] == airline]['Price'], bins=10, color='blue', edgecolor='black')\n",
    "    plt.title(airline)\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Histogram of Prices by Airline', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5988d69-1c16-47a3-b1e2-a70f3496c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnHot Encoding for categorical data and therfore which are Nominal Value\n",
    "Airline = df[['Airline']]\n",
    "Airline = pd.get_dummies(Airline, drop_first = True )\n",
    "Airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c48cff-f0c0-4dac-9aca-444ba16ccfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical value cleaning which is source\n",
    "df['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff8727-c667-47ca-b9b6-205255043fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot separate histograms for each source\n",
    "airlines = df['Source'].unique()\n",
    "n_airlines = len(airlines)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, airline in enumerate(airlines, 1):\n",
    "    plt.subplot((n_airlines // 3) + 1, 3, i)\n",
    "    plt.hist(df[df['Source'] == airline]['Price'], bins=10, color='blue', edgecolor='black')\n",
    "    plt.title(airline)\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Histogram of Prices by Source', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5f9414-6d06-42c6-8154-952e5ee13a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnHot Encoding for categorical data and therfore which are Nominal Value\n",
    "Source = df[['Source']]\n",
    "Source = pd.get_dummies(Source, drop_first = True )\n",
    "Source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291fe472-9b7a-48f8-bfc3-05cdbee2f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning another categorical feature Destintion\n",
    "df['Destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e27547-9efd-4737-aacc-18accf671d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnHot Encoding for categorical data and therfore which are Nominal Value\n",
    "Destination = df[['Destination']]\n",
    "Destination = pd.get_dummies(Destination, drop_first = True )\n",
    "Destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d1868-a320-4505-aabf-8d1e9e7adf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W'll drop routes\n",
    "df.drop('Route', axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980983d9-364f-4918-9a13-c5b4af234b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Additional_Info', axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7423d28c-27d7-452c-a0b5-2609d45a339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc6abe-42c8-4c32-9a50-a252c9903c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take another categorical variable called Total_Stops\n",
    "df['Total_Stops'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ccf69-4edd-413b-b973-b9e1e885b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Category = Label Encoder \n",
    "df.replace({\"1 stop\" : 1 , \"non-stop\": 0 , \"2 stops\": 2 , \"3 stops\" : 3 , \"4 stops\" : 4}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d5667-f343-4527-9b0d-3f59dc968742",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([df, Source, Destination, Airline], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca801dd-cdd7-4bca-bd12-019cdf60c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd309e7d-1123-4303-a41c-02a01e613386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Airline', 'Source', 'Destination'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8021e7-96e8-493a-9efa-b63d767f4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e24e86-48b9-4054-b3d7-6176c36be795",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea6e8b7-ba98-4ccb-9c67-976320b25993",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(\"/Users/krushna/Downloads/data-42/Test_set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e095f-2ede-4047-af4d-d657c9897f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25261533-3f76-43d0-8619-f8f254a85377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "print(\"Test data Info\")\n",
    "print(\"-\"*75)\n",
    "print(test_data.info())\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Null values :\")\n",
    "print(\"-\"*75)\n",
    "test_data.dropna(inplace = True)\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# EDA\n",
    "\n",
    "# Date_of_Journey\n",
    "test_data[\"Journey_day\"] = pd.to_datetime(test_data.Date_of_Journey, format=\"%d/%m/%Y\").dt.day\n",
    "test_data[\"Journey_month\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format = \"%d/%m/%Y\").dt.month\n",
    "test_data.drop([\"Date_of_Journey\"], axis = 1, inplace = True)\n",
    "\n",
    "# Dep_Time\n",
    "test_data[\"Dep_hour\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.hour\n",
    "test_data[\"Dep_min\"] = pd.to_datetime(test_data[\"Dep_Time\"]).dt.minute\n",
    "test_data.drop([\"Dep_Time\"], axis = 1, inplace = True)\n",
    "\n",
    "# Arrival_Time\n",
    "test_data[\"Arrival_hour\"] = pd.to_datetime(test_data.Arrival_Time).dt.hour\n",
    "test_data[\"Arrival_min\"] = pd.to_datetime(test_data.Arrival_Time).dt.minute\n",
    "test_data.drop([\"Arrival_Time\"], axis = 1, inplace = True)\n",
    "\n",
    "# Duration\n",
    "duration = list(test_data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration\n",
    "\n",
    "# Adding Duration column to test set\n",
    "test_data[\"Duration_hours\"] = duration_hours\n",
    "test_data[\"Duration_mins\"] = duration_mins\n",
    "test_data.drop([\"Duration\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Categorical data\n",
    "\n",
    "print(\"Airline\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Airline\"].value_counts())\n",
    "Airline = pd.get_dummies(test_data[\"Airline\"], drop_first= True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Source\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Source\"].value_counts())\n",
    "Source = pd.get_dummies(test_data[\"Source\"], drop_first= True)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Destination\")\n",
    "print(\"-\"*75)\n",
    "print(test_data[\"Destination\"].value_counts())\n",
    "Destination = pd.get_dummies(test_data[\"Destination\"], drop_first = True)\n",
    "\n",
    "# Additional_Info contains almost 80% no_info\n",
    "# Route and Total_Stops are related to each other\n",
    "test_data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n",
    "\n",
    "# Replacing Total_Stops\n",
    "test_data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n",
    "\n",
    "# Concatenate dataframe --> test_data + Airline + Source + Destination\n",
    "data_test = pd.concat([test_data, Airline, Source, Destination], axis = 1)\n",
    "\n",
    "data_test.drop([\"Airline\", \"Source\", \"Destination\"], axis = 1, inplace = True)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Shape of test data : \", data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d9e0d-64f7-4e7d-9b4e-387fd5aff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00af2be-a67f-43fd-b855-783fac14f288",
   "metadata": {},
   "source": [
    "# Feature Eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d29724-e657-462c-b118-f303264ff231",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d19cc6-a6a4-41da-9c22-d23a26e2717f",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa5065-df37-4906-b261-a1d5f781106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.loc[:, ['Total_Stops', 'Day_of_Journey', 'Month_of_Journey',\n",
    "       'Year_of_Journey', 'Dep_min', 'Dep_hour', 'Arr_minute', 'Arr_hour',\n",
    "       'duration_hours', 'duration_minute', 'Source_Chennai', 'Source_Delhi',\n",
    "       'Source_Kolkata', 'Source_Mumbai', 'Destination_Cochin',\n",
    "       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata',\n",
    "       'Destination_New Delhi', 'Airline_Air India', 'Airline_GoAir',\n",
    "       'Airline_IndiGo', 'Airline_Jet Airways', 'Airline_Multiple carriers',\n",
    "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
    "       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f3d0ca-e039-40cf-9ddd-63d5bf8dc8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b6cc08-46ee-4193-8e02-49a1d99a0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.iloc[: ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137403a-aeae-45bb-8b77-d17d44e7e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631ad77-4a4d-4e34-b5ed-0d358e1ee581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation bte indepndent and deendent features\n",
    "plt.figure(figsize = (18,18))\n",
    "sns.heatmap(train_data.corr(), annot= True, cmap = 'RdYlGn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c369240-e2f5-4549-8b2c-199b6517a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "selection = ExtraTreesRegressor()\n",
    "selection.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9eb6b-696e-4a67-ad6f-883a60e10de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selection.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24f365-f730-4812-9aa6-01d4ff425d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "feat_importances = pd.Series(selection.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b07d68-2efa-4cda-9a5a-4ca407f41adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model using Random Forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_rf = RandomForestRegressor()\n",
    "reg_rf.fit(X_train, y_train)\n",
    "y_pred = reg_rf.predict(X_test)\n",
    "reg_rf.score(X_train, y_train)\n",
    "sns.distplot(y_test-y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae90e0f-2e2c-49fd-8987-5020f024b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed2c40-cefa-4c37-b009-1bd13dafa34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE/(max(DV)-min(DV))\n",
    "\n",
    "2090.5509/(max(y)-min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdc5d5-07c0-47c8-b7a7-35f7c3895123",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36508713-2aee-4013-b151-cff2425416dc",
   "metadata": {},
   "source": [
    "# Model Hyper Tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3401c-bccb-463b-acdc-2d2f2611332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ddd1db-cd8e-4d4c-88bd-d6a0f14e5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95758d-b9ac-45ee-bb8b-d5f0d6d12058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44a6b8-de0d-4645-be93-c9adec26387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b653c53-fb5f-4c2f-be13-2f07dc671fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282b976-8112-4cb7-8746-ad3169660fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9dbe59-891c-46a3-a1f2-7b7091354873",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "sns.distplot(y_test-prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452057f3-52d1-450c-947f-084b4c1548eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10f6ed-c642-464b-9096-d1f959be0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a pickle file \n",
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "file = open('flight_rf.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(reg_rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12855d-2f29-47fc-b9ce-2755eb4bc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = open('flight_rf.pkl','rb')\n",
    "forest = pickle.load(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd47e0-c8ac-4594-b43f-92a2e66413e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de255cb7-f595-41eb-a77c-6c506b4d455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d18f3c-f73b-4642-8a33-4ccec3a7bd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
